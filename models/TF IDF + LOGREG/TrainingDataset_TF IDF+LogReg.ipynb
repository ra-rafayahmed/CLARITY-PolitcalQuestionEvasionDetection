{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"ailsntua/QEvasion\")"
      ],
      "metadata": {
        "id": "Mbfz1GZ2gtRX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"ailsntua/QEvasion\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "import joblib\n",
        "import re\n",
        "\n",
        "class TextClassifier:\n",
        "    def __init__(self, task='clarity'):\n",
        "        \"\"\"\n",
        "        Initialize classifier for response clarity/evasion classification\n",
        "\n",
        "        Args:\n",
        "            task: 'clarity' for 3-class (Clear Reply, Ambivalent Reply, Clear Non-Reply)\n",
        "                  'evasion' for fine-grained evasion types\n",
        "        \"\"\"\n",
        "        self.vectorizer = None\n",
        "        self.model = None\n",
        "        self.task = task\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"Basic text preprocessing\"\"\"\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "        # Remove special characters and digits\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "        # Remove extra whitespace\n",
        "        text = ' '.join(text.split())\n",
        "        return text\n",
        "\n",
        "    def load_data(self, filepath, question_col='question', answer_col='answer',\n",
        "                  label_col='clarity_label', combine_qa=True, show_evasion_stats=False):\n",
        "        \"\"\"\n",
        "        Load political interview Q&A dataset\n",
        "\n",
        "        Args:\n",
        "            filepath: Path to CSV file\n",
        "            question_col: Name of question column\n",
        "            answer_col: Name of answer column\n",
        "            label_col: Name of label column (clarity_label or evasion_label)\n",
        "            combine_qa: If True, concatenate question and answer as input\n",
        "            show_evasion_stats: If True, show evasion label distribution if available\n",
        "        \"\"\"\n",
        "        print(f\"Reading CSV file: {filepath}\")\n",
        "        try:\n",
        "            df = pd.read_csv(filepath)\n",
        "            print(f\"✓ CSV loaded successfully: {len(df)} rows, {len(df.columns)} columns\")\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error reading CSV: {e}\")\n",
        "            raise\n",
        "\n",
        "        # Check if required columns exist\n",
        "        print(f\"\\nChecking for required columns...\")\n",
        "        print(f\"Available columns: {list(df.columns)}\")\n",
        "\n",
        "        missing_cols = []\n",
        "        if question_col not in df.columns:\n",
        "            missing_cols.append(question_col)\n",
        "        if answer_col not in df.columns:\n",
        "            missing_cols.append(answer_col)\n",
        "        if label_col not in df.columns:\n",
        "            missing_cols.append(label_col)\n",
        "\n",
        "        if missing_cols:\n",
        "            raise KeyError(f\"Missing columns: {missing_cols}\")\n",
        "\n",
        "        print(f\"✓ All required columns found\")\n",
        "\n",
        "        # Remove rows with missing values in key columns\n",
        "        print(f\"\\nCleaning data...\")\n",
        "        original_len = len(df)\n",
        "        df = df.dropna(subset=[question_col, answer_col, label_col])\n",
        "        if len(df) < original_len:\n",
        "            print(f\"⚠ Removed {original_len - len(df)} rows with missing values\")\n",
        "\n",
        "        print(f\"Processing text data...\")\n",
        "        try:\n",
        "            if combine_qa:\n",
        "                # Combine question and answer for better context\n",
        "                texts = df.apply(\n",
        "                    lambda row: f\"Question: {str(row[question_col])} Answer: {str(row[answer_col])}\",\n",
        "                    axis=1\n",
        "                )\n",
        "            else:\n",
        "                # Use only answer\n",
        "                texts = df[answer_col].astype(str)\n",
        "\n",
        "            # Apply preprocessing\n",
        "            print(f\"Preprocessing text...\")\n",
        "            texts = texts.apply(self.preprocess_text)\n",
        "            print(f\"✓ Text processing completed\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error processing text: {e}\")\n",
        "            raise\n",
        "\n",
        "        labels = df[label_col]\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"DATASET SUMMARY\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Total samples: {len(texts)}\")\n",
        "        print(f\"\\n{label_col.upper()} Distribution:\")\n",
        "        print(labels.value_counts().to_string())\n",
        "\n",
        "        # Show evasion stats if requested and column exists\n",
        "        if show_evasion_stats:\n",
        "            try:\n",
        "                # Try to find evasion-related columns\n",
        "                evasion_cols = [col for col in df.columns if 'evasion' in col.lower()]\n",
        "\n",
        "                if evasion_cols:\n",
        "                    print(\"\\n\" + \"=\"*60)\n",
        "                    print(\"EVASION LABEL STATISTICS\")\n",
        "                    print(\"=\"*60)\n",
        "\n",
        "                    for evasion_col in evasion_cols:\n",
        "                        print(f\"\\n{evasion_col.upper()} Distribution:\")\n",
        "                        evasion_counts = df[evasion_col].value_counts()\n",
        "                        print(evasion_counts.to_string())\n",
        "\n",
        "                        # Show cross-tabulation with clarity labels if available\n",
        "                        if label_col != evasion_col and len(df[evasion_col].unique()) <= 20:\n",
        "                            print(f\"\\nCross-tabulation: {label_col} vs {evasion_col}\")\n",
        "                            try:\n",
        "                                crosstab = pd.crosstab(df[label_col], df[evasion_col], margins=True)\n",
        "                                print(crosstab.to_string())\n",
        "                            except Exception as e:\n",
        "                                print(f\"⚠ Could not create cross-tabulation: {e}\")\n",
        "                else:\n",
        "                    print(\"\\n⚠ No evasion columns found in dataset\")\n",
        "            except Exception as e:\n",
        "                print(f\"\\n⚠ Error showing evasion stats: {e}\")\n",
        "\n",
        "        return texts, labels\n",
        "\n",
        "    def train(self, X_train, y_train, tune_hyperparameters=True):\n",
        "        \"\"\"Train the TF-IDF + LogReg model\"\"\"\n",
        "\n",
        "        print(\"\\nInitializing TF-IDF Vectorizer...\")\n",
        "        # Initialize TF-IDF Vectorizer - optimized for political text\n",
        "        self.vectorizer = TfidfVectorizer(\n",
        "            max_features=10000,  # Political language can be diverse\n",
        "            ngram_range=(1, 3),  # Unigrams, bigrams, and trigrams for phrases\n",
        "            min_df=2,  # Ignore rare terms\n",
        "            max_df=0.9,  # Keep common political terms\n",
        "            stop_words='english',\n",
        "            sublinear_tf=True  # Use log scaling for term frequency\n",
        "        )\n",
        "\n",
        "        # Transform training data\n",
        "        print(\"Transforming text to TF-IDF features...\")\n",
        "        try:\n",
        "            X_train_tfidf = self.vectorizer.fit_transform(X_train)\n",
        "            print(f\"✓ TF-IDF matrix shape: {X_train_tfidf.shape}\")\n",
        "            print(f\"  - {X_train_tfidf.shape[0]} samples\")\n",
        "            print(f\"  - {X_train_tfidf.shape[1]} features\")\n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error during vectorization: {e}\")\n",
        "            raise\n",
        "\n",
        "        if tune_hyperparameters:\n",
        "            # Hyperparameter tuning with GridSearch\n",
        "            param_grid = {\n",
        "                'C': [0.1, 1, 10, 100],  # Wider range for better regularization\n",
        "                'penalty': ['l2'],\n",
        "                'solver': ['lbfgs'],\n",
        "                'max_iter': [500],\n",
        "                'class_weight': [None, 'balanced']  # Handle class imbalance\n",
        "            }\n",
        "\n",
        "            print(\"\\nPerforming hyperparameter tuning...\")\n",
        "            print(\"This may take a few minutes...\")\n",
        "            try:\n",
        "                grid_search = GridSearchCV(\n",
        "                    LogisticRegression(random_state=42),\n",
        "                    param_grid,\n",
        "                    cv=5,\n",
        "                    scoring='f1_weighted',  # Better for imbalanced classes\n",
        "                    n_jobs=-1,\n",
        "                    verbose=2\n",
        "                )\n",
        "                grid_search.fit(X_train_tfidf, y_train)\n",
        "\n",
        "                self.model = grid_search.best_estimator_\n",
        "                print(f\"\\n✓ Hyperparameter tuning completed!\")\n",
        "                print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "                print(f\"Best cross-validation F1 score: {grid_search.best_score_:.4f}\")\n",
        "            except Exception as e:\n",
        "                print(f\"✗ Error during hyperparameter tuning: {e}\")\n",
        "                print(\"Falling back to default parameters...\")\n",
        "                tune_hyperparameters = False\n",
        "\n",
        "        if not tune_hyperparameters:\n",
        "            # Train with default parameters\n",
        "            print(\"\\nTraining with default parameters...\")\n",
        "            try:\n",
        "                self.model = LogisticRegression(\n",
        "                    random_state=42,\n",
        "                    max_iter=500,\n",
        "                    C=1.0,\n",
        "                    class_weight='balanced',  # Handle imbalanced data\n",
        "                    verbose=1\n",
        "                )\n",
        "                self.model.fit(X_train_tfidf, y_train)\n",
        "                print(\"✓ Model training completed!\")\n",
        "            except Exception as e:\n",
        "                print(f\"✗ Error during model training: {e}\")\n",
        "                raise\n",
        "\n",
        "        return self\n",
        "\n",
        "    def evaluate(self, X_test, y_test):\n",
        "        \"\"\"Evaluate model performance\"\"\"\n",
        "        X_test_tfidf = self.vectorizer.transform(X_test)\n",
        "        y_pred = self.model.predict(X_test_tfidf)\n",
        "        y_proba = self.model.predict_proba(X_test_tfidf)\n",
        "\n",
        "        # Calculate average confidence (max probability for each prediction)\n",
        "        avg_confidence = np.max(y_proba, axis=1).mean()\n",
        "\n",
        "        print(\"\\n=== Model Evaluation ===\")\n",
        "        print(f\"Accuracy:       {accuracy_score(y_test, y_pred):.4f}\")\n",
        "        print(f\"Weighted F1:    {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "        print(f\"Macro F1:       {f1_score(y_test, y_pred, average='macro'):.4f}\")\n",
        "        print(f\"Avg Confidence: {avg_confidence:.4f}\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(classification_report(y_test, y_pred))\n",
        "        print(\"\\nConfusion Matrix:\")\n",
        "        print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "    def get_top_features(self, n=20):\n",
        "        \"\"\"Get most important features for each class\"\"\"\n",
        "        if self.model is None or self.vectorizer is None:\n",
        "            print(\"Model not trained yet!\")\n",
        "            return\n",
        "\n",
        "        feature_names = self.vectorizer.get_feature_names_out()\n",
        "\n",
        "        print(\"\\n=== Top Predictive Features per Class ===\")\n",
        "        for idx, class_name in enumerate(self.model.classes_):\n",
        "            coef = self.model.coef_[idx]\n",
        "            top_indices = np.argsort(coef)[-n:][::-1]\n",
        "            top_features = [(feature_names[i], coef[i]) for i in top_indices]\n",
        "\n",
        "            print(f\"\\n{class_name}:\")\n",
        "            for feat, score in top_features:\n",
        "                print(f\"  {feat}: {score:.4f}\")\n",
        "\n",
        "    def predict(self, texts):\n",
        "        \"\"\"Predict labels for new texts\"\"\"\n",
        "        if isinstance(texts, str):\n",
        "            texts = [texts]\n",
        "\n",
        "        processed_texts = [self.preprocess_text(text) for text in texts]\n",
        "        X_tfidf = self.vectorizer.transform(processed_texts)\n",
        "        predictions = self.model.predict(X_tfidf)\n",
        "        probabilities = self.model.predict_proba(X_tfidf)\n",
        "\n",
        "        return predictions, probabilities\n",
        "\n",
        "    def save_model(self, vectorizer_path='tfidf_vectorizer.pkl',\n",
        "                   model_path='logreg_model.pkl'):\n",
        "        \"\"\"Save trained model and vectorizer\"\"\"\n",
        "        joblib.dump(self.vectorizer, vectorizer_path)\n",
        "        joblib.dump(self.model, model_path)\n",
        "        print(f\"Model saved to {model_path}\")\n",
        "        print(f\"Vectorizer saved to {vectorizer_path}\")\n",
        "\n",
        "    def load_model(self, vectorizer_path='tfidf_vectorizer.pkl',\n",
        "                   model_path='logreg_model.pkl'):\n",
        "        \"\"\"Load pre-trained model and vectorizer\"\"\"\n",
        "        self.vectorizer = joblib.load(vectorizer_path)\n",
        "        self.model = joblib.load(model_path)\n",
        "        print(\"Model loaded successfully!\")\n",
        "\n",
        "\n",
        "# Training script for \"I Never Said That\" dataset from Hugging Face\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\"*60)\n",
        "    print(\"Training Response Clarity Classifier\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # QUICK DIAGNOSTICS - Check your environment\n",
        "    print(\"\\n[DIAGNOSTICS]\")\n",
        "    print(f\"Python packages:\")\n",
        "    print(f\"  pandas: {pd.__version__}\")\n",
        "    print(f\"  numpy: {np.__version__}\")\n",
        "    print(f\"  sklearn: {__import__('sklearn').__version__}\")\n",
        "\n",
        "    try:\n",
        "        from datasets import load_dataset\n",
        "        print(f\"  datasets: {__import__('datasets').__version__}\")\n",
        "    except ImportError:\n",
        "        print(\"\\n✗ 'datasets' library not found!\")\n",
        "        print(\"Installing datasets library...\")\n",
        "        import subprocess\n",
        "        subprocess.check_call(['pip', 'install', 'datasets'])\n",
        "        from datasets import load_dataset\n",
        "        print(\"✓ datasets library installed successfully!\")\n",
        "\n",
        "    import sys\n",
        "    print(f\"\\nMemory available: Checking...\")\n",
        "    try:\n",
        "        import psutil\n",
        "        mem = psutil.virtual_memory()\n",
        "        print(f\"  Total RAM: {mem.total / (1024**3):.1f} GB\")\n",
        "        print(f\"  Available RAM: {mem.available / (1024**3):.1f} GB\")\n",
        "    except:\n",
        "        print(\"  (psutil not available - can't check memory)\")\n",
        "\n",
        "    # Initialize classifiers (one for clarity, one for evasion)\n",
        "    clarity_classifier = TextClassifier(task='clarity')\n",
        "    evasion_classifier = TextClassifier(task='evasion')\n",
        "\n",
        "    # STEP 1: Load dataset from Hugging Face\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"STEP 1: LOADING DATASET FROM HUGGING FACE\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    try:\n",
        "        print(\"\\nDownloading dataset from Hugging Face: ailsntua/QEvasion\")\n",
        "        print(\"This may take a moment on first run...\")\n",
        "        ds = load_dataset(\"ailsntua/QEvasion\")\n",
        "\n",
        "        print(f\"✓ Dataset loaded successfully!\")\n",
        "        print(f\"\\nAvailable splits: {list(ds.keys())}\")\n",
        "\n",
        "        # Convert to pandas DataFrame for easier processing\n",
        "        if 'train' in ds:\n",
        "            df = ds['train'].to_pandas()\n",
        "        else:\n",
        "            split_name = list(ds.keys())[0]\n",
        "            print(f\"Using split: {split_name}\")\n",
        "            df = ds[split_name].to_pandas()\n",
        "\n",
        "        print(f\"\\nDataset shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "        print(f\"Columns: {list(df.columns)}\")\n",
        "\n",
        "        # Check for required columns\n",
        "        required_cols = ['question', 'interview_answer', 'clarity_label']\n",
        "        missing = [col for col in required_cols if col not in df.columns]\n",
        "\n",
        "        if missing:\n",
        "            print(f\"\\n⚠ Warning: Expected columns not found: {missing}\")\n",
        "            print(\"Available columns:\", list(df.columns))\n",
        "            print(\"\\nPlease check the dataset structure and update column names in the code.\")\n",
        "            exit()\n",
        "\n",
        "        # Remove rows with missing values\n",
        "        print(f\"\\nCleaning data...\")\n",
        "        original_len = len(df)\n",
        "        df = df.dropna(subset=['question', 'interview_answer', 'clarity_label'])\n",
        "        if len(df) < original_len:\n",
        "            print(f\"⚠ Removed {original_len - len(df)} rows with missing values\")\n",
        "\n",
        "        # Show dataset statistics\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"FULL DATASET STATISTICS\")\n",
        "        print(f\"{'='*60}\")\n",
        "        print(f\"Total samples: {len(df)}\")\n",
        "        print(f\"\\nCLARITY_LABEL Distribution:\")\n",
        "        print(df['clarity_label'].value_counts().to_string())\n",
        "\n",
        "        # Show evasion stats if column exists\n",
        "        has_evasion = 'evasion_label' in df.columns\n",
        "        if has_evasion:\n",
        "            print(f\"\\nEVASION_LABEL Distribution:\")\n",
        "            evasion_counts = df['evasion_label'].value_counts()\n",
        "            print(evasion_counts.to_string())\n",
        "\n",
        "            # Cross-tabulation\n",
        "            print(f\"\\nCross-tabulation: clarity_label vs evasion_label\")\n",
        "            crosstab = pd.crosstab(df['clarity_label'], df['evasion_label'], margins=True)\n",
        "            print(crosstab.to_string())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n✗ Error loading dataset: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        exit()\n",
        "\n",
        "    # STEP 2: Split into 90% train, 10% test\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"STEP 2: SPLITTING DATA (90% TRAIN / 10% TEST)\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Prepare texts by combining question and answer\n",
        "    print(\"\\nPreparing text data...\")\n",
        "    texts = df.apply(\n",
        "        lambda row: f\"Question: {str(row['question'])} Answer: {str(row['interview_answer'])}\",\n",
        "        axis=1\n",
        "    )\n",
        "\n",
        "    # Apply preprocessing\n",
        "    print(\"Preprocessing text...\")\n",
        "    texts = texts.apply(clarity_classifier.preprocess_text)\n",
        "    clarity_labels = df['clarity_label']\n",
        "\n",
        "    # Split with stratification to maintain class distribution\n",
        "    X_train, X_test, y_clarity_train, y_clarity_test = train_test_split(\n",
        "        texts,\n",
        "        clarity_labels,\n",
        "        test_size=0.10,\n",
        "        random_state=42,\n",
        "        stratify=clarity_labels\n",
        "    )\n",
        "\n",
        "    # Also split the original dataframe to get evasion labels for test set\n",
        "    df_train, df_test = train_test_split(\n",
        "        df,\n",
        "        test_size=0.10,\n",
        "        random_state=42,\n",
        "        stratify=df['clarity_label']\n",
        "    )\n",
        "\n",
        "    print(f\"✓ Data split completed!\")\n",
        "    print(f\"\\nTraining set: {len(X_train)} samples\")\n",
        "    print(f\"Test set: {len(X_test)} samples\")\n",
        "\n",
        "    print(f\"\\nTraining set clarity label distribution:\")\n",
        "    print(y_clarity_train.value_counts().to_string())\n",
        "\n",
        "    print(f\"\\nTest set clarity label distribution:\")\n",
        "    print(y_clarity_test.value_counts().to_string())\n",
        "\n",
        "    # Prepare evasion labels if available\n",
        "    if has_evasion:\n",
        "        y_evasion_train = df_train['evasion_label']\n",
        "        y_evasion_test = df_test['evasion_label']\n",
        "\n",
        "        print(f\"\\n--- TRAINING SET EVASION STATS ---\")\n",
        "        print(y_evasion_train.value_counts().to_string())\n",
        "\n",
        "        print(f\"\\n--- TEST SET EVASION STATS ---\")\n",
        "        print(y_evasion_test.value_counts().to_string())\n",
        "\n",
        "    # STEP 3: Train the clarity model\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 3: TRAINING CLARITY MODEL\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    USE_HYPERPARAMETER_TUNING = False\n",
        "\n",
        "    print(f\"\\nHyperparameter tuning: {USE_HYPERPARAMETER_TUNING}\")\n",
        "    if not USE_HYPERPARAMETER_TUNING:\n",
        "        print(\"(Set to True for better accuracy, but requires more time/memory)\")\n",
        "\n",
        "    try:\n",
        "        clarity_classifier.train(\n",
        "            X_train,\n",
        "            y_clarity_train,\n",
        "            tune_hyperparameters=USE_HYPERPARAMETER_TUNING\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"\\n✗ TRAINING FAILED: {e}\")\n",
        "        print(\"\\nTroubleshooting tips:\")\n",
        "        print(\"1. Try reducing max_features in the code\")\n",
        "        print(\"2. Make sure you have enough RAM\")\n",
        "        print(\"3. Check if your CSV has correct column names\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        exit()\n",
        "\n",
        "    print(\"\\n✓ Clarity model training completed!\")\n",
        "\n",
        "    # STEP 4: Evaluate clarity model on test set\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STEP 4: CLARITY MODEL EVALUATION\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    try:\n",
        "        y_clarity_pred = clarity_classifier.evaluate(X_test, y_clarity_test)\n",
        "    except Exception as e:\n",
        "        print(f\"\\n✗ Evaluation failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    # STEP 5: Train and evaluate evasion model (if evasion labels exist)\n",
        "    if has_evasion:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"STEP 5: TRAINING EVASION MODEL\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        try:\n",
        "            evasion_classifier.train(\n",
        "                X_train,\n",
        "                y_evasion_train,\n",
        "                tune_hyperparameters=USE_HYPERPARAMETER_TUNING\n",
        "            )\n",
        "            print(\"\\n✓ Evasion model training completed!\")\n",
        "        except Exception as e:\n",
        "            print(f\"\\n✗ Evasion training failed: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            has_evasion = False\n",
        "\n",
        "        if has_evasion:\n",
        "            print(\"\\n\" + \"=\"*60)\n",
        "            print(\"STEP 6: EVASION MODEL EVALUATION\")\n",
        "            print(\"=\"*60)\n",
        "\n",
        "            try:\n",
        "                y_evasion_pred = evasion_classifier.evaluate(X_test, y_evasion_test)\n",
        "            except Exception as e:\n",
        "                print(f\"\\n✗ Evasion evaluation failed: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "\n",
        "    # STEP 7: Analyze most predictive features\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"FEATURE ANALYSIS - CLARITY MODEL\")\n",
        "    print(\"=\"*60)\n",
        "    clarity_classifier.get_top_features(n=15)\n",
        "\n",
        "    if has_evasion:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"FEATURE ANALYSIS - EVASION MODEL\")\n",
        "        print(\"=\"*60)\n",
        "        evasion_classifier.get_top_features(n=15)\n",
        "\n",
        "    # STEP 8: Save the trained models\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SAVING MODELS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    clarity_classifier.save_model(\n",
        "        vectorizer_path='clarity_tfidf_vectorizer.pkl',\n",
        "        model_path='clarity_logreg_model.pkl'\n",
        "    )\n",
        "\n",
        "    if has_evasion:\n",
        "        evasion_classifier.save_model(\n",
        "            vectorizer_path='evasion_tfidf_vectorizer.pkl',\n",
        "            model_path='evasion_logreg_model.pkl'\n",
        "        )\n",
        "\n",
        "    # STEP 9: Test on some examples from test set\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SAMPLE PREDICTIONS FROM TEST SET\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Show 5 random examples from test set\n",
        "    sample_indices = np.random.choice(len(X_test), min(5, len(X_test)), replace=False)\n",
        "\n",
        "    for i, idx in enumerate(sample_indices):\n",
        "        text = X_test.iloc[idx]\n",
        "        true_clarity = y_clarity_test.iloc[idx]\n",
        "        pred_clarity, prob_clarity = clarity_classifier.predict([text])\n",
        "\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Example {i + 1}:\")\n",
        "        print(f\"{'='*50}\")\n",
        "        print(f\"Text: {text[:300]}...\")\n",
        "        print(f\"\\nTrue Clarity Label: {true_clarity}\")\n",
        "        print(f\"Predicted Clarity: {pred_clarity[0]}\")\n",
        "        print(f\"Clarity Confidence: {max(prob_clarity[0]):.2%}\")\n",
        "\n",
        "        if has_evasion:\n",
        "            true_evasion = y_evasion_test.iloc[idx]\n",
        "            pred_evasion, prob_evasion = evasion_classifier.predict([text])\n",
        "            print(f\"\\nTrue Evasion Label: {true_evasion}\")\n",
        "            print(f\"Predicted Evasion: {pred_evasion[0]}\")\n",
        "            print(f\"Evasion Confidence: {max(prob_evasion[0]):.2%}\")\n",
        "\n",
        "        print(f\"\\nClarity Correct: {'✓' if pred_clarity[0] == true_clarity else '✗'}\")\n",
        "        if has_evasion:\n",
        "            print(f\"Evasion Correct: {'✓' if pred_evasion[0] == true_evasion else '✗'}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TRAINING COMPLETE!\")\n",
        "    print(\"=\"*60)\n",
        "    print(\"\\nModels saved:\")\n",
        "    print(\"  - clarity_tfidf_vectorizer.pkl\")\n",
        "    print(\"  - clarity_logreg_model.pkl\")\n",
        "    if has_evasion:\n",
        "        print(\"  - evasion_tfidf_vectorizer.pkl\")\n",
        "        print(\"  - evasion_logreg_model.pkl\")\n",
        "    print(\"\\nYou can now use the trained models to predict on new data!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMTZjRDZgqmW",
        "outputId": "c97673e7-de99-4729-cf5f-b02e77cb5460"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Training Response Clarity Classifier\n",
            "============================================================\n",
            "\n",
            "[DIAGNOSTICS]\n",
            "Python packages:\n",
            "  pandas: 2.2.2\n",
            "  numpy: 2.0.2\n",
            "  sklearn: 1.6.1\n",
            "  datasets: 4.0.0\n",
            "\n",
            "Memory available: Checking...\n",
            "  Total RAM: 12.7 GB\n",
            "  Available RAM: 10.5 GB\n",
            "\n",
            "============================================================\n",
            "STEP 1: LOADING DATASET FROM HUGGING FACE\n",
            "============================================================\n",
            "\n",
            "Downloading dataset from Hugging Face: ailsntua/QEvasion\n",
            "This may take a moment on first run...\n",
            "✓ Dataset loaded successfully!\n",
            "\n",
            "Available splits: ['train', 'test']\n",
            "\n",
            "Dataset shape: 3448 rows, 20 columns\n",
            "Columns: ['title', 'date', 'president', 'url', 'question_order', 'interview_question', 'interview_answer', 'gpt3.5_summary', 'gpt3.5_prediction', 'question', 'annotator_id', 'annotator1', 'annotator2', 'annotator3', 'inaudible', 'multiple_questions', 'affirmative_questions', 'index', 'clarity_label', 'evasion_label']\n",
            "\n",
            "Cleaning data...\n",
            "\n",
            "============================================================\n",
            "FULL DATASET STATISTICS\n",
            "============================================================\n",
            "Total samples: 3448\n",
            "\n",
            "CLARITY_LABEL Distribution:\n",
            "clarity_label\n",
            "Ambivalent         2040\n",
            "Clear Reply        1052\n",
            "Clear Non-Reply     356\n",
            "\n",
            "EVASION_LABEL Distribution:\n",
            "evasion_label\n",
            "Explicit               1052\n",
            "Dodging                 706\n",
            "Implicit                488\n",
            "General                 386\n",
            "Deflection              381\n",
            "Declining to answer     145\n",
            "Claims ignorance        119\n",
            "Clarification            92\n",
            "Partial/half-answer      79\n",
            "\n",
            "Cross-tabulation: clarity_label vs evasion_label\n",
            "evasion_label    Claims ignorance  Clarification  Declining to answer  Deflection  Dodging  Explicit  General  Implicit  Partial/half-answer   All\n",
            "clarity_label                                                                                                                                     \n",
            "Ambivalent                      0              0                    0         381      706         0      386       488                   79  2040\n",
            "Clear Non-Reply               119             92                  145           0        0         0        0         0                    0   356\n",
            "Clear Reply                     0              0                    0           0        0      1052        0         0                    0  1052\n",
            "All                           119             92                  145         381      706      1052      386       488                   79  3448\n",
            "\n",
            "============================================================\n",
            "STEP 2: SPLITTING DATA (90% TRAIN / 10% TEST)\n",
            "============================================================\n",
            "\n",
            "Preparing text data...\n",
            "Preprocessing text...\n",
            "✓ Data split completed!\n",
            "\n",
            "Training set: 3103 samples\n",
            "Test set: 345 samples\n",
            "\n",
            "Training set clarity label distribution:\n",
            "clarity_label\n",
            "Ambivalent         1836\n",
            "Clear Reply         947\n",
            "Clear Non-Reply     320\n",
            "\n",
            "Test set clarity label distribution:\n",
            "clarity_label\n",
            "Ambivalent         204\n",
            "Clear Reply        105\n",
            "Clear Non-Reply     36\n",
            "\n",
            "--- TRAINING SET EVASION STATS ---\n",
            "evasion_label\n",
            "Explicit               947\n",
            "Dodging                641\n",
            "Implicit               439\n",
            "General                347\n",
            "Deflection             338\n",
            "Declining to answer    132\n",
            "Claims ignorance       105\n",
            "Clarification           83\n",
            "Partial/half-answer     71\n",
            "\n",
            "--- TEST SET EVASION STATS ---\n",
            "evasion_label\n",
            "Explicit               105\n",
            "Dodging                 65\n",
            "Implicit                49\n",
            "Deflection              43\n",
            "General                 39\n",
            "Claims ignorance        14\n",
            "Declining to answer     13\n",
            "Clarification            9\n",
            "Partial/half-answer      8\n",
            "\n",
            "============================================================\n",
            "STEP 3: TRAINING CLARITY MODEL\n",
            "============================================================\n",
            "\n",
            "Hyperparameter tuning: False\n",
            "(Set to True for better accuracy, but requires more time/memory)\n",
            "\n",
            "Initializing TF-IDF Vectorizer...\n",
            "Transforming text to TF-IDF features...\n",
            "✓ TF-IDF matrix shape: (3103, 10000)\n",
            "  - 3103 samples\n",
            "  - 10000 features\n",
            "\n",
            "Training with default parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model training completed!\n",
            "\n",
            "✓ Clarity model training completed!\n",
            "\n",
            "============================================================\n",
            "STEP 4: CLARITY MODEL EVALUATION\n",
            "============================================================\n",
            "\n",
            "=== Model Evaluation ===\n",
            "Accuracy:       0.6232\n",
            "Weighted F1:    0.6276\n",
            "Macro F1:       0.5762\n",
            "Avg Confidence: 0.5462\n",
            "\n",
            "Classification Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     Ambivalent       0.73      0.68      0.70       204\n",
            "Clear Non-Reply       0.42      0.61      0.50        36\n",
            "    Clear Reply       0.53      0.52      0.53       105\n",
            "\n",
            "       accuracy                           0.62       345\n",
            "      macro avg       0.56      0.60      0.58       345\n",
            "   weighted avg       0.64      0.62      0.63       345\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[138  22  44]\n",
            " [  9  22   5]\n",
            " [ 42   8  55]]\n",
            "\n",
            "============================================================\n",
            "STEP 5: TRAINING EVASION MODEL\n",
            "============================================================\n",
            "\n",
            "Initializing TF-IDF Vectorizer...\n",
            "Transforming text to TF-IDF features...\n",
            "✓ TF-IDF matrix shape: (3103, 10000)\n",
            "  - 3103 samples\n",
            "  - 10000 features\n",
            "\n",
            "Training with default parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Model training completed!\n",
            "\n",
            "✓ Evasion model training completed!\n",
            "\n",
            "============================================================\n",
            "STEP 6: EVASION MODEL EVALUATION\n",
            "============================================================\n",
            "\n",
            "=== Model Evaluation ===\n",
            "Accuracy:       0.3275\n",
            "Weighted F1:    0.3304\n",
            "Macro F1:       0.3380\n",
            "Avg Confidence: 0.2593\n",
            "\n",
            "Classification Report:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "   Claims ignorance       0.44      0.50      0.47        14\n",
            "      Clarification       0.47      0.78      0.58         9\n",
            "Declining to answer       0.37      0.77      0.50        13\n",
            "         Deflection       0.25      0.35      0.29        43\n",
            "            Dodging       0.43      0.32      0.37        65\n",
            "           Explicit       0.54      0.29      0.37       105\n",
            "            General       0.22      0.28      0.24        39\n",
            "           Implicit       0.20      0.24      0.22        49\n",
            "Partial/half-answer       0.00      0.00      0.00         8\n",
            "\n",
            "           accuracy                           0.33       345\n",
            "          macro avg       0.32      0.39      0.34       345\n",
            "       weighted avg       0.37      0.33      0.33       345\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 7  0  2  1  3  0  0  1  0]\n",
            " [ 0  7  0  0  2  0  0  0  0]\n",
            " [ 0  0 10  0  1  0  0  1  1]\n",
            " [ 1  0  2 15  3  4  8  9  1]\n",
            " [ 1  2  3  8 21  7  9 13  1]\n",
            " [ 3  4  4 21 11 30 16 16  0]\n",
            " [ 2  2  3  4  4  4 11  7  2]\n",
            " [ 1  0  3 10  3 10  6 12  4]\n",
            " [ 1  0  0  2  1  1  1  2  0]]\n",
            "\n",
            "============================================================\n",
            "FEATURE ANALYSIS - CLARITY MODEL\n",
            "============================================================\n",
            "\n",
            "=== Top Predictive Features per Class ===\n",
            "\n",
            "Ambivalent:\n",
            "  question believe: 1.1618\n",
            "  called: 1.0715\n",
            "  answer okay: 1.0649\n",
            "  country: 0.9811\n",
            "  political: 0.9175\n",
            "  great: 0.9150\n",
            "  believe: 0.9038\n",
            "  care: 0.8839\n",
            "  president: 0.8473\n",
            "  met: 0.8244\n",
            "  trade: 0.8029\n",
            "  confidence: 0.7802\n",
            "  hoax: 0.7786\n",
            "  states: 0.7742\n",
            "  answer just: 0.7736\n",
            "\n",
            "Clear Non-Reply:\n",
            "  dont know: 2.6360\n",
            "  stuffed: 1.8707\n",
            "  hear: 1.8260\n",
            "  answer dont: 1.6963\n",
            "  dont: 1.6412\n",
            "  im going: 1.4082\n",
            "  wish: 1.3970\n",
            "  answer wont: 1.3785\n",
            "  questions: 1.3564\n",
            "  transcript: 1.3121\n",
            "  ask: 1.2809\n",
            "  answered: 1.2671\n",
            "  good question: 1.2320\n",
            "  answer excuse: 1.2236\n",
            "  answer dont know: 1.1945\n",
            "\n",
            "Clear Reply:\n",
            "  yes: 2.3278\n",
            "  answer yes: 1.3368\n",
            "  answer sure: 1.2174\n",
            "  deal: 1.1475\n",
            "  absolutely: 0.9267\n",
            "  did: 0.9250\n",
            "  billion: 0.9076\n",
            "  way: 0.8365\n",
            "  taken: 0.8308\n",
            "  come: 0.8305\n",
            "  answer looking: 0.8286\n",
            "  followup: 0.8241\n",
            "  dont think: 0.8184\n",
            "  think: 0.8091\n",
            "  years: 0.7847\n",
            "\n",
            "============================================================\n",
            "FEATURE ANALYSIS - EVASION MODEL\n",
            "============================================================\n",
            "\n",
            "=== Top Predictive Features per Class ===\n",
            "\n",
            "Claims ignorance:\n",
            "  dont know: 4.5147\n",
            "  dont: 3.0615\n",
            "  know: 2.8747\n",
            "  answer dont know: 2.7114\n",
            "  soon: 2.3438\n",
            "  wish: 1.9021\n",
            "  answer havent: 1.7345\n",
            "  havent: 1.7198\n",
            "  transcript: 1.5763\n",
            "  answer dont: 1.5314\n",
            "  long time: 1.2905\n",
            "  offer: 1.2369\n",
            "  new: 1.1911\n",
            "  dont remember: 1.1372\n",
            "  thats bad: 1.1350\n",
            "\n",
            "Clarification:\n",
            "  hear: 2.6612\n",
            "  sorry: 2.2155\n",
            "  im sorry: 2.0520\n",
            "  answer say: 1.9946\n",
            "  answer excuse: 1.8771\n",
            "  question request: 1.6430\n",
            "  stuffed: 1.5712\n",
            "  jonathan: 1.5497\n",
            "  dont understand: 1.5472\n",
            "  question answer: 1.4993\n",
            "  opinion: 1.4870\n",
            "  table: 1.4750\n",
            "  definition: 1.4359\n",
            "  questions: 1.4169\n",
            "  drop: 1.3811\n",
            "\n",
            "Declining to answer:\n",
            "  im going: 2.5137\n",
            "  ask: 2.2522\n",
            "  comment: 2.0835\n",
            "  answer wont: 1.9459\n",
            "  answered: 1.8155\n",
            "  answer dont want: 1.7449\n",
            "  going comment: 1.6517\n",
            "  april: 1.6330\n",
            "  im: 1.5790\n",
            "  im going comment: 1.4841\n",
            "  answer theyre: 1.4827\n",
            "  lot: 1.4544\n",
            "  going make: 1.3767\n",
            "  news: 1.3322\n",
            "  stuffed: 1.3152\n",
            "\n",
            "Deflection:\n",
            "  country: 1.3620\n",
            "  people: 1.1058\n",
            "  lot: 1.0285\n",
            "  things: 1.0101\n",
            "  biden: 0.9862\n",
            "  great: 0.9583\n",
            "  going: 0.9177\n",
            "  administration: 0.9166\n",
            "  youre: 0.8938\n",
            "  care: 0.8888\n",
            "  talks: 0.8840\n",
            "  just: 0.8815\n",
            "  democrats: 0.8287\n",
            "  got: 0.8209\n",
            "  obama: 0.8126\n",
            "\n",
            "Dodging:\n",
            "  answer okay: 1.4692\n",
            "  sir answer: 0.9919\n",
            "  answer just: 0.9023\n",
            "  answer yes: 0.8938\n",
            "  did: 0.8144\n",
            "  answer right: 0.7878\n",
            "  called: 0.7747\n",
            "  happened: 0.7333\n",
            "  sir: 0.7222\n",
            "  yes ahead: 0.7207\n",
            "  concessions: 0.6652\n",
            "  right let: 0.6388\n",
            "  stop: 0.6298\n",
            "  collusion: 0.6239\n",
            "  lunch: 0.6123\n",
            "\n",
            "Explicit:\n",
            "  yes: 2.1946\n",
            "  answer yes: 1.4130\n",
            "  deal: 0.8078\n",
            "  answer sure: 0.7877\n",
            "  did: 0.7244\n",
            "  billion: 0.6490\n",
            "  troops: 0.6423\n",
            "  ahead: 0.6402\n",
            "  absolutely: 0.5897\n",
            "  dont think: 0.5838\n",
            "  taken: 0.5733\n",
            "  followup: 0.5714\n",
            "  question considering: 0.5638\n",
            "  having: 0.5570\n",
            "  answer looking: 0.5276\n",
            "\n",
            "General:\n",
            "  answer yes: 1.1312\n",
            "  working: 1.0863\n",
            "  care: 1.0856\n",
            "  want: 1.0604\n",
            "  great: 0.9959\n",
            "  government: 0.9146\n",
            "  implemented: 0.9094\n",
            "  believe: 0.8414\n",
            "  working hard: 0.8392\n",
            "  fantastic: 0.8294\n",
            "  probably: 0.8290\n",
            "  republican: 0.8183\n",
            "  kind: 0.8032\n",
            "  prepared: 0.7916\n",
            "  big: 0.7839\n",
            "\n",
            "Implicit:\n",
            "  answer think: 0.9138\n",
            "  changed: 0.9072\n",
            "  years: 0.8323\n",
            "  think: 0.8134\n",
            "  models: 0.8055\n",
            "  said: 0.7694\n",
            "  tax: 0.7556\n",
            "  time: 0.7533\n",
            "  secretary: 0.7375\n",
            "  partners: 0.7371\n",
            "  john: 0.7282\n",
            "  pay: 0.6905\n",
            "  job: 0.6680\n",
            "  people: 0.6667\n",
            "  confidence: 0.6581\n",
            "\n",
            "Partial/half-answer:\n",
            "  dr: 2.0422\n",
            "  response: 1.5344\n",
            "  accept: 1.3586\n",
            "  political: 1.2622\n",
            "  friends: 1.2586\n",
            "  certain: 1.1974\n",
            "  respond: 1.1951\n",
            "  current: 1.1718\n",
            "  commutations: 1.1602\n",
            "  cuba: 1.1318\n",
            "  process: 1.1307\n",
            "  example: 1.1301\n",
            "  jeff: 1.1020\n",
            "  ban: 1.0964\n",
            "  needs: 1.0767\n",
            "\n",
            "============================================================\n",
            "SAVING MODELS\n",
            "============================================================\n",
            "Model saved to clarity_logreg_model.pkl\n",
            "Vectorizer saved to clarity_tfidf_vectorizer.pkl\n",
            "Model saved to evasion_logreg_model.pkl\n",
            "Vectorizer saved to evasion_tfidf_vectorizer.pkl\n",
            "\n",
            "============================================================\n",
            "SAMPLE PREDICTIONS FROM TEST SET\n",
            "============================================================\n",
            "\n",
            "==================================================\n",
            "Example 1:\n",
            "==================================================\n",
            "Text: question opinion on the deal between hunt oil and the kurdish regional government answer our embassy also expressed concern about it i knew nothing about the deal i need to know exactly how it happened to the extent that it does undermine the ability for the government to come up with an oil revenue...\n",
            "\n",
            "True Clarity Label: Clear Reply\n",
            "Predicted Clarity: Clear Reply\n",
            "Clarity Confidence: 47.58%\n",
            "\n",
            "True Evasion Label: Explicit\n",
            "Predicted Evasion: Explicit\n",
            "Evasion Confidence: 17.71%\n",
            "\n",
            "Clarity Correct: ✓\n",
            "Evasion Correct: ✓\n",
            "\n",
            "==================================================\n",
            "Example 2:\n",
            "==================================================\n",
            "Text: question how many cigarettes a day do you now smoke answer well thefirst of all the new law that was put in place is not about me its about the next generation of kids coming up so i think its fair margaret to just say that you just think its neat to ask me about my smoking as opposed to it being re...\n",
            "\n",
            "True Clarity Label: Ambivalent\n",
            "Predicted Clarity: Ambivalent\n",
            "Clarity Confidence: 40.54%\n",
            "\n",
            "True Evasion Label: Dodging\n",
            "Predicted Evasion: Dodging\n",
            "Evasion Confidence: 27.85%\n",
            "\n",
            "Clarity Correct: ✓\n",
            "Evasion Correct: ✓\n",
            "\n",
            "==================================================\n",
            "Example 3:\n",
            "==================================================\n",
            "Text: question what is your position on italy being part of the plus group handling the iranian crisis issue are you in favor of italys participation or are you waiting to see what might happen answer inaudiblethe pplus and i told silvio id seriously consider it i also made it clear however that all of us...\n",
            "\n",
            "True Clarity Label: Clear Reply\n",
            "Predicted Clarity: Clear Reply\n",
            "Clarity Confidence: 57.26%\n",
            "\n",
            "True Evasion Label: Explicit\n",
            "Predicted Evasion: General\n",
            "Evasion Confidence: 18.78%\n",
            "\n",
            "Clarity Correct: ✓\n",
            "Evasion Correct: ✗\n",
            "\n",
            "==================================================\n",
            "Example 4:\n",
            "==================================================\n",
            "Text: question will you pull out of the accord answer im not going to use the name nafta i refuse to use it ive seen thousands of plants and factories close ive seen millions of jobs lost to auto companies that moved i mean mexico has percent of our auto business now because of nafta under our deal its no...\n",
            "\n",
            "True Clarity Label: Ambivalent\n",
            "Predicted Clarity: Ambivalent\n",
            "Clarity Confidence: 39.00%\n",
            "\n",
            "True Evasion Label: Implicit\n",
            "Predicted Evasion: Deflection\n",
            "Evasion Confidence: 21.38%\n",
            "\n",
            "Clarity Correct: ✓\n",
            "Evasion Correct: ✗\n",
            "\n",
            "==================================================\n",
            "Example 5:\n",
            "==================================================\n",
            "Text: question how much of the significant new us troop buildup outlined by the person being addressed is due to concerns about the rise of china answer well first with respect to these new initiatives this rotational deployment is significant because what it allows us to do is to not only build capacity ...\n",
            "\n",
            "True Clarity Label: Ambivalent\n",
            "Predicted Clarity: Ambivalent\n",
            "Clarity Confidence: 72.46%\n",
            "\n",
            "True Evasion Label: Deflection\n",
            "Predicted Evasion: General\n",
            "Evasion Confidence: 25.10%\n",
            "\n",
            "Clarity Correct: ✓\n",
            "Evasion Correct: ✗\n",
            "\n",
            "============================================================\n",
            "TRAINING COMPLETE!\n",
            "============================================================\n",
            "\n",
            "Models saved:\n",
            "  - clarity_tfidf_vectorizer.pkl\n",
            "  - clarity_logreg_model.pkl\n",
            "  - evasion_tfidf_vectorizer.pkl\n",
            "  - evasion_logreg_model.pkl\n",
            "\n",
            "You can now use the trained models to predict on new data!\n"
          ]
        }
      ]
    }
  ]
}